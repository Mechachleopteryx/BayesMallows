#' Compute the posterior distribution for the Mallows model.
#'
#' @param R A matrix of ranked items. See \code{\link{create_ranking}} if you
#'   have an ordered set of items that needs to be converted to rankings. If
#'   \code{P} is provided, \code{R} is an optional initial value of the
#'   rankings, generated by \code{\link{generate_initial_ranking}}.
#' @param P A dataframe with the transitive closure of pairwise comparisons. If
#'   it has class \code{BayesMallowsTC}, generated by
#'   \code{\link{generate_transitive_closure}}, this will be used. Otherwise,
#'   \code{\link{generate_transitive_closure}} will be called on this dataframe.
#' @param metric The distance metric to use. Currently available ones are
#'   \code{"footrule"}, \code{"spearman"}, \code{"kendall"}, \code{"cayley"},
#'   and \code{"hamming"}.
#' @param num_clusters Number of clusters. Defaults to 1, which means no
#'   clustering.
#' @param lambda Parameter for the prior distribution of \code{alpha}. Defaults
#'   to 0.1.
#' @param nmc Number of Monte Carlo samples to keep.
#' @param L Step size of the leap-and-shift proposal distribution. Defaults to
#'   NULL, which means that it is automatically set to n/5.
#' @param sd_alpha Standard deviation of the proposal distribution for alpha.
#' @param alpha_init Initial value of alpha.
#' @param alpha_jump How many times should we sample \code{rho} between each
#'   time we sample \code{alpha}. Setting \code{alpha_jump} to a high number can
#'   significantly speed up computation time, since we then do not have to do
#'   expensive computation of the partition function.
#' @param thinning Keep every \code{thinning} iteration of \code{rho}.
#' @param aug_diag_thinning The interval in which we save augmentation
#'   diagnostics.
#'
#' @return A list of class BayesMallows.
#' @references \insertRef{vitelli2018}{BayesMallows}
#' @seealso \code{\link{assess_convergence}}, \code{\link{plot.BayesMallows}}.
#' @export
#' @importFrom rlang .data
compute_mallows <- function(R = NULL,
                            P = NULL,
                            metric = "footrule",
                            num_clusters = 1,
                            lambda = 0.1,
                            nmc = 3000,
                            L = NULL,
                            sd_alpha = 0.1,
                            alpha_init = 1,
                            alpha_jump = 1,
                            thinning = 1,
                            aug_diag_thinning = 100
                            ){

  # Check that at most one of R and P is set
  stopifnot(!is.null(R) || !is.null(P))


  # Deal with pairwise comparisons. Generate R compatible with them.
  if(!is.null(P)){

    if(!("BayesMallowsTC" %in% class(P))){
      P <- generate_transitive_closure(P)
    }

    # Find all the constrained elements per assessor
    constrained <- dplyr::group_by(P, .data$assessor)
    constrained <- dplyr::summarise(constrained,
                                    items = list(unique(c(.data$bottom_item, .data$top_item))))
    constrained <- tidyr::unnest(constrained)
    constrained <- as.matrix(constrained)

    P <- as.matrix(P)

    if(is.null(R)){
      R <- generate_initial_ranking(P)
    }
  } else {
    constrained <- NULL
  }

  # If there are no missing values nor preference, increase aug_diag_thinning
  if(is.null(P) && sum(is.na(R)) == 0){
    aug_diag_thinning <- nmc
  }

  # Check that all rows of R are proper permutations
  if(!all(apply(R, 1, validate_permutation))){
    stop("Not valid permutation.")
  }

  # Check that we do not jump over all alphas
  stopifnot(alpha_jump < nmc)

  # Check that we do not jump over all rhos
  stopifnot(thinning < nmc)

  # Find the number of items
  n_items <- ncol(R)

  # Set L if it is not alredy set.
  if(is.null(L)) L <- floor(n_items / 5)

  # Extract the right sequence of cardinalities, if relevant
  if(metric %in% c("footrule", "spearman")){
    # Extract the relevant rows from partition_function_data
    # Note that we need to evaluate the right-hand side, in particular metric,
    # to avoid confusion with columns of the tibble
    relevant_params <- dplyr::filter(partition_function_data,
                                     .data$num_items == !!n_items,
                                     .data$metric == !!metric
    )

    type <- dplyr::pull(relevant_params, type)

    if(type == "cardinalities") {
      cardinalities <- unlist(relevant_params$values)
      is_fit <- NULL
    } else if(type == "importance_sampling"){
      cardinalities <- NULL
      is_fit <- unlist(relevant_params$values)
    } else {
      stop("Precomputed partition function not available yet.")
    }

  } else if (metric %in% c("cayley", "hamming", "kendall")) {
    cardinalities <- NULL
    is_fit <- NULL
  } else {
    stop(paste("Unknown metric", metric))
  }



  # Transpose R to get samples along columns, since we typically want
  # to extract one sample at a time. armadillo is column major, just like R
  fit <- run_mcmc(R = t(R),
                  nmc = nmc,
                  pairwise = P,
                  constrained = constrained,
                  cardinalities = cardinalities,
                  is_fit = is_fit,
                  metric = metric,
                  n_clusters = num_clusters,
                  lambda = lambda,
                  L = L,
                  sd_alpha = sd_alpha,
                  alpha_init = alpha_init,
                  alpha_jump = alpha_jump,
                  thinning = thinning,
                  aug_diag_thinning = aug_diag_thinning
                  )

  # If no data augmentation has happened, do not include aug_acceptance
  # Otherwise, convert to fraction
  if(!fit$any_missing && !fit$augpair) {
    fit$aug_acceptance <- NULL
    fit$aug_diag_thinning <- NULL
  } else {
    fit$aug_acceptance <- fit$aug_acceptance / aug_diag_thinning
  }

  # Add names of item
  if(!is.null(colnames(R))) {
    rownames(fit$rho) <- colnames(R)
  } else {
    rownames(fit$rho) <- paste("Item", seq(from = 1, to = nrow(fit$rho), by = 1))
  }

  fit$items <- rownames(fit$rho)
  # Tidy MCMC results

  fit <- tidy_mcmc(fit)


  # Add class attribute
  class(fit) <- "BayesMallows"

  return(fit)

}
