% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/compute_mallows.R
\name{compute_mallows}
\alias{compute_mallows}
\title{Preference Learning with the Mallows Rank Model}
\usage{
compute_mallows(rankings = NULL, preferences = NULL,
  metric = "footrule", n_clusters = 1L, nmc = 2000L,
  leap_size = NULL, rho_init = NULL, thinning = 1L,
  alpha_prop_sd = 0.1, alpha_init = 1, alpha_jump = 1L,
  lambda = 0.001, psi = 10L, include_wcd = (n_clusters > 1),
  save_augmented_data = FALSE, is_fit = NULL)
}
\arguments{
\item{rankings}{A matrix of ranked items, of size \code{n_assessors x
n_items}. See \code{\link{create_ranking}} if you have an ordered set of
items that need to be converted to rankings. If \code{preferences} is
provided, \code{rankings} is an optional initial value of the rankings,
generated by \code{\link{generate_initial_ranking}}. If \code{rankings}
has column names, these are assumed to be the names of the items.}

\item{preferences}{A dataframe with pairwise comparisons, with 3 columns,
named \code{assessor}, \code{bottom_item}, and \code{top_item}, and one row
for each stated preference. Given a set of pairwise preferences, generate a
transitive closure using \code{\link{generate_transitive_closure}}. This
will give \code{preferences} the class \code{"BayesMallowsTC"}. Otherwise,
\code{compute_mallows} will call \code{\link{generate_transitive_closure}}
will be called on \code{preferences} before computations are done. In the
current version, the pairwise preferences are assumed to be mutually
compatible.}

\item{metric}{A character string specifying the distance metric to use in the
Bayesian Mallows Model. Available options are \code{"footrule"},
\code{"spearman"}, \code{"kendall"}, \code{"cayley"}, and \code{"hamming"}.
The distance given by \code{metric} is also used to compute within-cluster
distances, when \code{include_wcd = TRUE}.}

\item{n_clusters}{Integer specifying the number of clusters, i.e., the number
of mixture components to use. Defaults to \code{1L}, which means no clustering is
performed.}

\item{nmc}{Integer specifying the number of iteration of the Metropolis-Hastings
algorithm. Defaults to \code{2000L}. See \code{\link{assess_convergence}} for
tools to check convergence of the Markov chain.}

\item{leap_size}{Integer specifying the step size of the leap-and-shift
proposal distribution. Defaults to NULL, which means that it is set based
on the data to \code{floor(n_assessors / 5)}.}

\item{rho_init}{Numeric vector specifying the initial value of the latent
consensus ranking \eqn{\rho}. Defaults to NULL, which means that the initial
value is set randomly. If \code{rho_init} is provided when \code{n_clusters
> 1}, each mixture component \eqn{\rho_{c}} gets the same initial value.}

\item{thinning}{Integer specifying the thinning to be performed in the
Metropolis- Hastings algorithm. Defaults to \code{1L}. \code{compute_mallows} save
every \code{thinning}th value of \eqn{\rho}. If \code{save_augmented_data}
is \code{TRUE}, then also the augmented data are saved every
\code{thinning}th iteration. See \insertCite{link2011;textual}{BayesMallows} for
a discussion of when it is appropriate to use thinning, and when it is not.}

\item{alpha_prop_sd}{Numeric value specifying the standard deviation of the
lognormal proposal distribution used for \eqn{\alpha} in the Metropolis-Hastings
algorithm. Defaults to \code{0.1}.}

\item{alpha_init}{Numeric value specifying the initial value of the scale parameter
\eqn{\alpha}. Defaults to \code{1}. When \code{n_clusters > 1}, each mixture
component \eqn{\alpha_{c}} gets the same initial value.}

\item{alpha_jump}{Integer specifying how many times to sample \eqn{\rho} between each
sampling of \eqn{\alpha}. In other words, how many times to jump over \eqn{\alpha}
while sampling \eqn{\rho}, and possibly other parameters like augmented ranks
\eqn{\tilde{R}} or cluster assignments \eqn{z}. Setting \code{alpha_jump} to a
high number can speed up computation time, by reducing the number of times the
partition function for the Mallows model needs to be computed.}

\item{lambda}{Numeric value specifying the rate parameter of the exponential prior
distribution of \eqn{\alpha}, \eqn{\pi(\alpha) = \lambda \exp{(-\lambda \alpha)}}.
Defaults to \code{0.1}. When \code{n_cluster > 1}, each mixture component
\eqn{\alpha_{c}} has the same prior distribution.}

\item{psi}{Integer specifying the concentration parameter \eqn{\psi} of the
Dirichlet prior distribution used for the cluster probabilities
\eqn{\tau_{1}, \tau_{2}, \dots, \tau_{C}}, where \eqn{C} is the value of
\code{n_clusters}. Defaults to \code{10L}. When \code{n_clusters = 1},
this argument is not used.}

\item{include_wcd}{Logical indicating whether to store the within-cluster
distances computing during the Metropolis-Hastings algorithm. Defaults to
\code{TRUE} if \code{n_clusters > 1} and otherwise \code{FALSE}. Setting
\code{include_wcd = TRUE} is useful when deciding the number of mixture
components to include, and is required by \code{\link{plot_elbow}}.}

\item{save_augmented_data}{Logical specifying whether or not to save the
augmented rankings every \code{thinning}th iteration, for the case of missing
data or pairwise preferences. Defaults to \code{FALSE}. Saving augmented data
is useful for predicting the rankings each assessor would give to the items
not yet ranked, and is required by \code{\link{plot_top_k}}.}

\item{is_fit}{Importance sampling estimate of the partition function,
computed with \code{\link{estimate_partition_function}}.}
}
\value{
A list of class BayesMallows.
}
\description{
Compute the posterior distributions of the parameters of the Bayesian Mallows
Rank Model \insertCite{mallows1957,vitelli2018}{BayesMallows}, given rankings
or preferences stated by a set of assessors. \code{compute_mallows} always
returns posterior distributions of the latent consensus ranking \eqn{\rho} and
the scale parameter \eqn{\alpha}. Several distance measures are supported, and
the preferences can take the form of complete or incomplete rankings, as well
as pairwise preferences. \code{compute_mallows} can also compute mixtures of
Mallows models, for clustering of assessors with similar preferences.
}
\examples{
# Analysis of complete rankings
# The example datasets potato_visual and potato_weighing contain complete
# rankings of 20 items, by 12 assessors. We first analyse these using the Mallows
# model:
model_fit <- compute_mallows(potato_visual)
# We study the trace plot of the parameters
# alpha is the default
assess_convergence(model_fit)
# When studying convergence of rho, we can also specify which items to plot
assess_convergence(model_fit, type = "rho", items = 1:5)
# Based on these plots, we conclude that the Markov chain has converged well
# before 1,000 iterations. We hence set burnin = 1000.
# Next, we use the generic plot function to study the posterior distributions
# of alpha and rho
plot(model_fit, burnin = 1000)
plot(model_fit, burnin = 1000, type = "rho", items = 1:20)
# We can also compute the CP consensus posterior ranking
compute_cp_consensus(model_fit, burnin = 1000)
# And we can compute the posterior intervals:
# First we compute the interval for alpha
compute_posterior_intervals(model_fit, burnin = 1000, parameter = "alpha")
# Then we compute the interval for all the items
compute_posterior_intervals(model_fit, burnin = 1000, parameter = "rho")

}
\references{
\insertAllCited{}
}
